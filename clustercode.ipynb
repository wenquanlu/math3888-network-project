{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from community import community_louvain\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import markov_clustering as mc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing\n",
    "G0 = nx.read_weighted_edgelist(\"4932.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_proteins = pd.read_csv(\"essential_proteins.csv\", header = None)\n",
    "\n",
    "for node in list(G0.nodes()):\n",
    "    if node[5:] in list(essential_proteins[1]):\n",
    "        G0.remove_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_cc = max(nx.connected_components(G0),key=len)\n",
    "G = G0.subgraph(largest_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = nx.eigenvector_centrality(G)\n",
    "centrality = sorted((v, f\"{c:0.2f}\") for v, c in centrality.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4932.YGL007W', '4932.YOR183W', '4932.YOL075C', '4932.YDR528W', '4932.YMR169C']\n",
      "['4932.YMR232W', '4932.YLR398C', '4932.YPR061C', '4932.YGR286C', '4932.YOL052C-A']\n",
      "['4932.YER066C-A', '4932.YHR151C', '4932.YLR040C', '4932.YFL064C', '4932.YMR230W-A']\n",
      "['4932.YPR007C', '4932.YGL089C', '4932.YOL015W', '4932.YOR343W-A', '4932.YLR250W']\n",
      "['4932.YBL100W-C', '4932.YIL141W', '4932.YDR365W-B', '4932.YLR160C', '4932.YAR064W']\n"
     ]
    }
   ],
   "source": [
    "with open('neighbouring_clusters_complete_mean_minus.pickle', 'rb') as f:\n",
    "    neighbours = pickle.load(f)\n",
    "max_centrality_nodes=[] \n",
    "for cluster in neighbours[0:5]:\n",
    "    cluster_centrality = {k: centrality[k] for k in cluster}\n",
    "    maxes = []\n",
    "    for i in range(5):\n",
    "        currentmax = max(cluster_centrality, key=cluster_centrality.get)\n",
    "        maxes.append(currentmax)\n",
    "        del cluster_centrality[currentmax]\n",
    "    max_centrality_nodes.append(maxes)\n",
    "# max_centrality_nodes[i] is the node with maximum centrality from cluster i\n",
    "max_centrality_nodes\n",
    "node_names = list(G.nodes())\n",
    "\n",
    "for cluster in max_centrality_nodes:\n",
    "    group = []\n",
    "    for node in cluster:\n",
    "        group.append(node_names[node])\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4932.YPR191W': 0.03117769538443003, '4932.YBL045C': 0.028181757413446314, '4932.YOR065W': 0.022376468983793394, '4932.YDR529C': 0.02147919685119501, '4932.Q0105': 0.01846637227125854, '4932.YFR033C': 0.018184217462420663, '4932.Q0045': 0.017944214297046752, '4932.YEL024W': 0.017463668464672566, '4932.YHR051W': 0.01721470656284861, '4932.YGL191W': 0.016376086059344718, '4932.YML129C': 0.015993347847020542, '4932.YGL187C': 0.015744259936979133, '4932.YJL166W': 0.013942220395586062, '4932.YNL052W': 0.011419240816077895, '4932.Q0250': 0.01071829122835436, '4932.YGR183C': 0.009599099902086619, '4932.YLR038C': 0.009446348024671465, '4932.YJR048W': 0.009187125846495253, '4932.YDR493W': 0.008935192551567654, '4932.YIL157C': 0.008760437359938297, '4932.Q0275': 0.007589596410107988, '4932.YHR001W-A': 0.007476516422665861, '4932.YER141W': 0.007156697702360371, '4932.YEL039C': 0.006824278638574975, '4932.YIL111W': 0.006505131883016079, '4932.YDR375C': 0.006411022879154982, '4932.YGR112W': 0.0060259319831947765, '4932.YPL215W': 0.005626834130184977, '4932.YKL087C': 0.005523464027699873, '4932.Q0120': 0.005368790752129655, '4932.YPL132W': 0.005268250673001509, '4932.YLL009C': 0.004975457623248709, '4932.YBR037C': 0.0049235443853238095, '4932.YMR256C': 0.004767463850259794, '4932.YML030W': 0.004630657299264001, '4932.YGR062C': 0.004606455179085316, '4932.Q0070': 0.004527571315678354, '4932.YPL172C': 0.004448618095281505, '4932.YMR145C': 0.004374423147598079, '4932.Q0060': 0.004361150774563496, '4932.YML120C': 0.004223885936727736, '4932.YGL226W': 0.004154538142570399, '4932.YLR395C': 0.0040744696044544395, '4932.YJR077C': 0.0032724572730108824, '4932.YGR174C': 0.0028596791496489555, '4932.Q0115': 0.00278873103024594, '4932.Q0110': 0.00278873103024594, '4932.YLL018C-A': 0.002599815483849142, '4932.Q0065': 0.002488962908830046, '4932.YLR203C': 0.0024022975098404852, '4932.YPL189C-A': 0.0022815676699468133, '4932.Q0050': 0.0021494996251297796, '4932.YDL085W': 0.0020227058758153144, '4932.YIL114C': 0.002022481521588392, '4932.YJL131C': 0.0019806226951961455, '4932.YJL003W': 0.0017069218370907953, '4932.YNR018W': 0.0016734397026640163, '4932.YAL039C': 0.0015994878508698185, '4932.YHR116W': 0.0015950716628112603, '4932.YJL062W-A': 0.0014912381024134646, '4932.YDR119W-A': 0.0012059573611628348, '4932.YGR243W': 0.0009851859447328546, '4932.YJR034W': 0.0008289725716144224, '4932.YHR162W': 0.0007942931019866359, '4932.YER004W': 0.0005393554384333581, '4932.YBR085W': 0.0005111872021300145, '4932.YLR077W': 0.0004615925401269942, '4932.YER058W': 0.0004365712034948012, '4932.YDL181W': 0.0004287422177632431, '4932.Q0055': 0.00037467637482257944, '4932.YPR021C': 0.0003365045112619206, '4932.YGL080W': 0.0002986822959063933, '4932.YOR037W': 0.00025544616049648757, '4932.YPR010C-A': 0.00016209963969206006, '4932.YMR003W': 0.0, '4932.YDL189W': 0.0, '4932.Q0075': 0.0, '4932.YGL188C': 0.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('neighbouring_clusters_complete_mean_minus.pickle', 'rb') as f:\n",
    "    neighbours = pickle.load(f)\n",
    "with open('target_cluster.pickle', 'rb') as f:\n",
    "    target = pickle.load(f)\n",
    "\n",
    "\n",
    "for cluster in neighbours[0:1]:\n",
    "    betweenness = nx.betweenness_centrality(G.subgraph(target.union(cluster)))\n",
    "    #betweenness = sorted(betweenness.items(), key = lambda x:x.value(), reverse=True)\n",
    "    betweenness = {k:v for k,v in sorted(betweenness.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    print(betweenness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "subgraph() missing 1 required positional argument: 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-112f338fe8ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcentrality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbetweenness_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mcentrality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{c:0.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcentrality\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: subgraph() missing 1 required positional argument: 'nodes'"
     ]
    }
   ],
   "source": [
    "max_centrality_nodes=[] \n",
    "for cluster in neighbours[0:5]:\n",
    "    cluster_centrality = {k: centrality[k] for k in cluster}\n",
    "    maxes = []\n",
    "    for i in range(5):\n",
    "        currentmax = max(cluster_centrality, key=cluster_centrality.get)\n",
    "        maxes.append(currentmax)\n",
    "        del cluster_centrality[currentmax]\n",
    "    max_centrality_nodes.append(maxes)\n",
    "# max_centrality_nodes[i] is the node with maximum centrality from cluster i\n",
    "max_centrality_nodes\n",
    "node_names = list(G.nodes())\n",
    "\n",
    "for cluster in max_centrality_nodes:\n",
    "    group = []\n",
    "    for node in cluster:\n",
    "        group.append(node_names[node])\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('neighbouring_clusters_sum.pickle', 'rb') as f:\n",
    "    neighbours = pickle.load(f)\n",
    "    #for i in range(len(neighbours)):\n",
    "        #print(len(neighbours[i].intersection(neighbours2[i]))/len(neighbours[i].union(neighbours2[i])))\n",
    "\n",
    "max_centrality_nodes=[] \n",
    "for cluster in neighbours[0:5]:\n",
    "    cluster_centrality = {k: centrality[k] for k in cluster}\n",
    "    maxes = []\n",
    "    for i in range(5):\n",
    "        currentmax = max(cluster_centrality, key=cluster_centrality.get)\n",
    "        maxes.append(currentmax)\n",
    "        del cluster_centrality[currentmax]\n",
    "    max_centrality_nodes.append(maxes)\n",
    "# max_centrality_nodes[i] is the node with maximum centrality from cluster i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4932.YGL007W', '4932.YOR183W', '4932.YOL075C', '4932.YDR528W', '4932.YMR169C']\n",
      "['4932.YPR007C', '4932.YGL089C', '4932.YOL015W', '4932.YOR343W-A', '4932.YLR250W']\n",
      "['4932.YER066C-A', '4932.YHR151C', '4932.YLR040C', '4932.YFL064C', '4932.YMR230W-A']\n",
      "['4932.YAR066W', '4932.YER137C-A', '4932.YLR091W', '4932.YAL031C', '4932.YOR348C']\n",
      "['4932.YBL100W-C', '4932.YIL141W', '4932.YDR365W-B', '4932.YLR160C', '4932.YAR064W']\n"
     ]
    }
   ],
   "source": [
    "max_centrality_nodes\n",
    "node_names = list(G.nodes())\n",
    "\n",
    "for cluster in max_centrality_nodes:\n",
    "    group = []\n",
    "    for node in cluster:\n",
    "        group.append(node_names[node])\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('neighbouring_clusters_minus.pickle', 'rb') as f:\n",
    "    neighbours = pickle.load(f)\n",
    "max_centrality_nodes=[] \n",
    "for cluster in neighbours[0:5]:\n",
    "    cluster_centrality = {k: centrality[k] for k in cluster}\n",
    "    maxes = []\n",
    "    for i in range(5):\n",
    "        currentmax = max(cluster_centrality, key=cluster_centrality.get)\n",
    "        maxes.append(currentmax)\n",
    "        del cluster_centrality[currentmax]\n",
    "    max_centrality_nodes.append(maxes)\n",
    "# max_centrality_nodes[i] is the node with maximum centrality from cluster i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4932.YGL007W', '4932.YOR183W', '4932.YOL075C', '4932.YDR528W', '4932.YMR169C']\n",
      "['4932.YPR007C', '4932.YGL089C', '4932.YOL015W', '4932.YOR343W-A', '4932.YLR250W']\n",
      "['4932.YER066C-A', '4932.YHR151C', '4932.YLR040C', '4932.YFL064C', '4932.YMR230W-A']\n",
      "['4932.YAR066W', '4932.YER137C-A', '4932.YLR091W', '4932.YAL031C', '4932.YOR348C']\n",
      "['4932.YBL100W-C', '4932.YIL141W', '4932.YDR365W-B', '4932.YLR160C', '4932.YAR064W']\n"
     ]
    }
   ],
   "source": [
    "max_centrality_nodes\n",
    "node_names = list(G.nodes())\n",
    "\n",
    "for cluster in max_centrality_nodes:\n",
    "    group = []\n",
    "    for node in cluster:\n",
    "        group.append(node_names[node])\n",
    "    print(group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4932.YGL007W', '4932.YOR183W', '4932.YOL075C', '4932.YDR528W', '4932.YMR169C']\n",
      "['4932.YPR007C', '4932.YGL089C', '4932.YOL015W', '4932.YOR343W-A', '4932.YLR250W']\n",
      "['4932.YER066C-A', '4932.YHR151C', '4932.YLR040C', '4932.YFL064C', '4932.YMR230W-A']\n",
      "['4932.YAR066W', '4932.YER137C-A', '4932.YLR091W', '4932.YAL031C', '4932.YOR348C']\n",
      "['4932.YBL100W-C', '4932.YIL141W', '4932.YDR365W-B', '4932.YLR160C', '4932.YAR064W']\n"
     ]
    }
   ],
   "source": [
    "centrality = nx.degree_centrality(G)\n",
    "centrality = sorted((v, f\"{c:0.2f}\") for v, c in centrality.items())\n",
    "with open('neighbouring_clusters_sum.pickle', 'rb') as f:\n",
    "    neighbours = pickle.load(f)\n",
    "max_centrality_nodes=[] \n",
    "for cluster in neighbours[0:5]:\n",
    "    cluster_centrality = {k: centrality[k] for k in cluster}\n",
    "    maxes = []\n",
    "    for i in range(5):\n",
    "        currentmax = max(cluster_centrality, key=cluster_centrality.get)\n",
    "        maxes.append(currentmax)\n",
    "        del cluster_centrality[currentmax]\n",
    "    max_centrality_nodes.append(maxes)\n",
    "# max_centrality_nodes[i] is the node with maximum centrality from cluster i\n",
    "max_centrality_nodes\n",
    "node_names = list(G.nodes())\n",
    "\n",
    "for cluster in max_centrality_nodes:\n",
    "    group = []\n",
    "    for node in cluster:\n",
    "        group.append(node_names[node])\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
